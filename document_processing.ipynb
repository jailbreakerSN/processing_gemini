{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9"
      },
      "source": [
        "# Document Processing with Gemini\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fdocument-processing%2Fdocument_processing.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>       \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/document-processing/document_processing.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://goo.gle/4jhBze9\">\n",
        "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb49ff2efb96"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Holt Skinner](https://github.com/holtskinner), [Drew Gillson](https://github.com/drewgillson) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In today's information-driven world, the volume of digital documents generated daily is staggering. From emails and reports to legal contracts and scientific papers, businesses and individuals alike are inundated with vast amounts of textual data. Extracting meaningful insights from these documents efficiently and accurately has become a paramount challenge.\n",
        "\n",
        "Document processing involves a range of tasks, including text extraction, classification, summarization, and translation, among others. Traditional methods often rely on rule-based algorithms or statistical models, which may struggle with the nuances and complexities of natural language.\n",
        "\n",
        "Generative AI offers a promising alternative to understand, generate, and manipulate text using natural language prompting. Gemini on Vertex AI allows these models to be used in a scalable manner through:\n",
        "\n",
        "- [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) in the Cloud Console\n",
        "- [Vertex AI REST API](https://cloud.google.com/vertex-ai/docs/reference/rest)\n",
        "- [Google Gen AI SDK for Python](https://cloud.google.com/vertex-ai/generative-ai/docs/sdks/overview)\n",
        "\n",
        "For more information, see the [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) documentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkcqHrrwMAo"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use the Gemini API in Vertex AI with the Google Gen AI SDK for Python to process PDF documents.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Install the SDK\n",
        "- Use the Gemini 2.0 Flash model to:\n",
        "  - Extract structured entities from an unstructured document\n",
        "  - Classify document types\n",
        "  - Combine classification and entity extraction into a single workflow\n",
        "  - Answer questions from documents\n",
        "  - Summarize documents\n",
        "  - Extract Table Data as HTML\n",
        "  - Translate documents\n",
        "  - Compare and contrast similar documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nEPojogw-g"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dependency-management-markdown"
      },
      "source": [
        "### Dependency Management for Projects\n",
        "\n",
        "While using `%pip install` is convenient for interactive notebooks, standalone Python projects benefit from more structured dependency management. This ensures that your project can be reliably set up in different environments and by other collaborators.\n",
        "\n",
        "**1. `requirements.txt`:**\n",
        "   - A common way to manage dependencies is by listing them in a `requirements.txt` file.\n",
        "   - You can generate a `requirements.txt` file that captures all packages in your current environment using:\n",
        "     ```bash\n",
        "     pip freeze > requirements.txt\n",
        "     ```\n",
        "   - To install dependencies from this file in a new environment, you would run:\n",
        "     ```bash\n",
        "     pip install -r requirements.txt\n",
        "     ```\n",
        "   - **Recommendation**: For a project, it's better to manually create and maintain your `requirements.txt` file, listing only the direct dependencies your project needs (e.g., `google-genai`, `pydantic`). `pip freeze` captures all packages, including indirect dependencies and those unrelated to your current project, which can make the environment less predictable.\n",
        "\n",
        "**2. Virtual Environments:**\n",
        "   - It is highly recommended to use virtual environments in conjunction with `requirements.txt`.\n",
        "   - Virtual environments (created using tools like `venv` or `conda`) isolate your project's dependencies from your global Python installation and other projects. This prevents version conflicts and ensures that your project has exactly the dependencies it needs.\n",
        "   - **Example with `venv`**:\n",
        "     ```bash\n",
        "     # Create a virtual environment\n",
        "     python -m venv my-project-env\n",
        "     # Activate it (on macOS/Linux)\n",
        "     source my-project-env/bin/activate\n",
        "     # Activate it (on Windows)\n",
        "     # .\\my-project-env\\Scripts\\activate\n",
        "     \n",
        "     # Install dependencies into the virtual environment\n",
        "     pip install -r requirements.txt\n",
        "     ```\n",
        "\n",
        "**3. Advanced Dependency Management Tools:**\n",
        "   - For more complex projects, consider using tools like [Poetry](https://python-poetry.org/) or [Pipenv](https://pipenv.pypa.io/en/latest/).\n",
        "   - These tools offer more advanced features, including:\n",
        "     - Dependency resolution (solving compatible versions of all direct and indirect dependencies).\n",
        "     - Project packaging and building.\n",
        "     - Integrated virtual environment management.\n",
        "     - Often use a `pyproject.toml` file instead of just `requirements.txt`.\n",
        "\n",
        "Adopting these practices leads to more reproducible, maintainable, and shareable Python projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google import genai\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lslYAvw37JGQ"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from enum import Enum\n",
        "import json\n",
        "from html.parser import HTMLParser # For parsing HTML table output\n",
        "\n",
        "import google.api_core.exceptions\n",
        "from IPython.display import Markdown, display\n",
        "from google.genai.types import GenerateContentConfig, Part\n",
        "from pydantic import BaseModel, Field, create_model_from_json_schema # Pydantic for data validation and schema definition\n",
        "\n",
        "PDF_MIME_TYPE = \"application/pdf\"\n",
        "JSON_MIME_TYPE = \"application/json\"\n",
        "ENUM_MIME_TYPE = \"text/x.enum\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "helper-function-cell"
      },
      "outputs": [],
      "source": [
        "def make_gemini_request(client, model_id, contents, generation_config):\n",
        "    \"\"\"Makes a request to the Gemini API and handles common errors.\n",
        "    \n",
        "    Args:\n",
        "        client: The Gemini API client.\n",
        "        model_id: The ID of the Gemini model to use.\n",
        "        contents: The contents of the prompt to send to the model.\n",
        "        generation_config: The generation configuration for the request.\n",
        "        \n",
        "    Returns:\n",
        "        The API response object if successful, None otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=model_id,\n",
        "            contents=contents,\n",
        "            config=generation_config\n",
        "        )\n",
        "        return response\n",
        "    except google.api_core.exceptions.InvalidArgument as e:\n",
        "        print(f\"An API error occurred (InvalidArgument): {type(e).__name__} - {e}\")\n",
        "        return None\n",
        "    except google.api_core.exceptions.NotFound as e:\n",
        "        print(f\"An API error occurred (NotFound): {type(e).__name__} - {e}\")\n",
        "        return None\n",
        "    except google.api_core.exceptions.ServiceUnavailable as e:\n",
        "        print(f\"An API error occurred (ServiceUnavailable): {type(e).__name__} - {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {type(e).__name__} - {e}\")\n",
        "        return None # Fallback for any other unexpected errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTMywdzUORIA"
      },
      "source": [
        "### Load the Gemini 2.0 Flash model\n",
        "\n",
        "Gemini 2.0 Flash (`gemini-2.0-flash`) is a multimodal model that supports multimodal prompts. You can include text, image(s), and video in your prompt requests and get text or code responses.\n",
        "\n",
        "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e771399cfc79"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type: \"string\"}\n",
        "# Using gemini-2.0-flash-001, a fast and versatile multimodal model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy75sLb-yjNn"
      },
      "source": [
        "## Entity Extraction\n",
        "\n",
        "[Named Entity Extraction](https://en.wikipedia.org/wiki/Named-entity_recognition) is a technique of Natural Language Processing to identify specific fields and values from unstructured text. For example, you can find key-value pairs from a filled out form, or get all of the important data from an invoice categorized by the type. The Gemini API can perform entity extraction when provided with a schema describing the desired entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a75f6e4bd54"
      },
      "source": [
        "### Extract entities from an invoice\n",
        "\n",
        "In this example, you will use a sample invoice and get all of the information in a structured format.\n",
        "\n",
        "The `entity_extraction_system_instruction` guides the model to act as an entity extraction specialist. It emphasizes extracting values directly from the document without normalization, ensuring the extracted data accurately reflects the source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0841cb312d46"
      },
      "outputs": [],
      "source": [
        "entity_extraction_system_instruction = \"\"\"You are a document entity extraction specialist. Given a document, your task is to extract the text value of the entities provided in the schema.\n",
        "- The values must only include text found in the document\n",
        "- Do not normalize any entity values.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "802016a08f79"
      },
      "source": [
        "We will use [Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) to tell the model which fields need to be extracted. The response schema is specified using Pydantic models in the `response_schema` parameter of `GenerateContentConfig`. The model output will then strictly follow this schema, returning a JSON object that can be parsed into the Pydantic model. Setting `response_mime_type` to `application/json` ensures the output is JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "608a06507932"
      },
      "outputs": [],
      "source": [
        "# Pydantic models define the schema for entity extraction.\n",
        "# Each class represents an entity, and its fields represent the attributes to extract.\n",
        "class Address(BaseModel):\n",
        "    street: str | None = Field(None, example=\"123 Main St\", description=\"Street name and number.\")\n",
        "    city: str | None = Field(None, example=\"Springfield\", description=\"City name.\")\n",
        "    state: str | None = Field(None, example=\"IL\", description=\"State or region.\")\n",
        "    postal_code: str | None = Field(None, example=\"62704\", description=\"Postal or ZIP code.\")\n",
        "    country: str | None = Field(None, example=\"USA\", description=\"Country name or code (e.g., USA).\" )\n",
        "\n",
        "\n",
        "class LineItem(BaseModel):\n",
        "    amount: float = Field(..., example=100.00, description=\"Total amount for this line item (quantity * unit_price).\")\n",
        "    description: str | None = Field(None, example=\"Laptop\", description=\"Description of the product or service.\")\n",
        "    product_code: str | None = Field(None, example=\"LPT-001\", description=\"Product or service code, if available.\")\n",
        "    quantity: int = Field(..., example=2, description=\"Number of units.\")\n",
        "    unit: str | None = Field(None, example=\"pcs\", description=\"Unit of measure (e.g., pcs, kg, hrs).\")\n",
        "    unit_price: float = Field(..., example=50.00, description=\"Price per unit.\")\n",
        "\n",
        "\n",
        "class VAT(BaseModel):\n",
        "    amount: float = Field(..., example=20.00, description=\"VAT amount for this category/item.\")\n",
        "    category_code: str | None = Field(None, example=\"A\", description=\"VAT category code, if applicable.\")\n",
        "    tax_amount: float | None = Field(None, example=5.00, description=\"Tax amount component of the VAT (if specified separately).\" )\n",
        "    tax_rate: float | None = Field(\n",
        "        None, example=10.0, description=\"VAT rate as a percentage (e.g., 10.0 for 10%).\"\n",
        "    ) \n",
        "    total_amount: float = Field(..., example=200.00, description=\"Total amount for items under this VAT category, including VAT.\")\n",
        "\n",
        "\n",
        "class Party(BaseModel):\n",
        "    name: str = Field(..., example=\"Google\", description=\"Name of the party (e.g., supplier or receiver).\" )\n",
        "    street: str | None = Field(None, example=\"456 Business Rd\", description=\"Street address of the party.\")\n",
        "    city: str | None = Field(None, example=\"Metropolis\", description=\"City of the party.\")\n",
        "    state: str | None = Field(None, example=\"NY\", description=\"State or region of the party.\")\n",
        "    postal_code: str | None = Field(None, example=\"10001\", description=\"Postal code of the party.\")\n",
        "    country: str | None = Field(None, example=\"USA\", description=\"Country of the party.\")\n",
        "    email: str | None = Field(None, example=\"contact@google.com\", description=\"Contact email address of the party.\")\n",
        "    phone: str | None = Field(None, example=\"+1-555-1234\", description=\"Contact phone number of the party.\")\n",
        "    website: str | None = Field(None, example=\"https://google.com\", description=\"Website URL of the party.\")\n",
        "    tax_id: str | None = Field(None, example=\"123456789\", description=\"Tax identification number (e.g., VAT ID, EIN).\" )\n",
        "    registration: str | None = Field(None, example=\"Reg-98765\", description=\"Business registration number, if applicable.\")\n",
        "    iban: str | None = Field(None, example=\"US1234567890123456789\", description=\"International Bank Account Number, if applicable.\")\n",
        "    payment_ref: str | None = Field(None, example=\"INV-2024-001\", description=\"Payment reference or identifier.\")\n",
        "\n",
        "\n",
        "class Invoice(BaseModel):\n",
        "    invoice_id: str = Field(..., example=\"INV-2024-001\", description=\"Unique identifier for the invoice.\")\n",
        "    invoice_date: str = Field(..., example=\"2024-02-03\", description=\"Date the invoice was issued (YYYY-MM-DD).\" )\n",
        "    supplier: Party = Field(..., description=\"Details of the supplier or vendor.\")\n",
        "    receiver: Party = Field(..., description=\"Details of the receiver or customer.\")\n",
        "    line_items: list[LineItem] = Field(..., description=\"List of individual line items on the invoice.\")\n",
        "    vat: list[VAT] = Field(description=\"List of VAT (Value Added Tax) details, if applicable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91dcaf17c2ce"
      },
      "source": [
        "For this example, we will download a PDF document to local storage and send the file bytes to the API for processing.\n",
        "\n",
        "You can view the document [here](https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/invoice.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42b044f767e3"
      },
      "outputs": [],
      "source": [
        "# Download a PDF from Google Cloud Storage\n",
        "! gsutil cp \"gs://cloud-samples-data/generative-ai/pdf/invoice.pdf\" ./invoice.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzqjpEiryjNo"
      },
      "outputs": [],
      "source": [
        "# Load file bytes\n",
        "with open(\"invoice.pdf\", \"rb\") as f:\n",
        "    file_bytes = f.read()\n",
        "\n",
        "# Define generation config for Invoice: temperature=0 for deterministic, structured output based on the Pydantic schema.\n",
        "invoice_config = GenerateContentConfig(\n",
        "    system_instruction=entity_extraction_system_instruction,\n",
        "    temperature=0, # Use 0 for deterministic and structured output based on schema\n",
        "    response_schema=Invoice,\n",
        "    response_mime_type=JSON_MIME_TYPE,\n",
        ")\n",
        "# Send to Gemini API using the helper function\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        \"The following document is an invoice.\", # Contextual prompt for the model\n",
        "        Part.from_bytes(data=file_bytes, mime_type=PDF_MIME_TYPE),\n",
        "    ],\n",
        "    generation_config=invoice_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "131e8044cf70"
      },
      "source": [
        "We can load the extracted data as an object using the `response.parsed` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63f7f16fabc7"
      },
      "outputs": [],
      "source": [
        "invoice_data = response.parsed\n",
        "print(\"\\n-------Extracted Entities--------\")\n",
        "print(invoice_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c82b9d10e9d1"
      },
      "source": [
        "Or the response can then be parsed as JSON into a Python dictionary for use in other applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce9731cb0a84"
      },
      "outputs": [],
      "source": [
        "json_object = json.loads(response.text)\n",
        "print(json_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7cdda6aa720"
      },
      "source": [
        "You can see that Gemini extracted all of the relevant fields from the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dca9fa02c05"
      },
      "source": [
        "### Extract entities from a payslip\n",
        "\n",
        "Let's try with another type of document, a payslip or paystub. This uses the same `entity_extraction_system_instruction` but a different Pydantic schema (`Payslip`).\n",
        "\n",
        "In this example, we will use a document hosted on Google Cloud Storage and process it by passing the URI.\n",
        "\n",
        "You can view the document [here](https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/earnings_statement.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3ca20cd3f738"
      },
      "outputs": [],
      "source": [
        "class Payslip(BaseModel):\n",
        "    employee_id: str = Field(..., description=\"Unique identifier for the employee.\")\n",
        "    employee_name: str = Field(..., description=\"Full name of the employee.\")\n",
        "    pay_period_start: date = Field(..., description=\"Start date of the pay period (YYYY-MM-DD).\")\n",
        "    pay_period_end: date = Field(..., description=\"End date of the pay period (YYYY-MM-DD).\")\n",
        "    gross_income: float = Field(..., description=\"Total income before any deductions.\")\n",
        "    federal_tax: float = Field(..., description=\"Amount deducted for federal income tax.\")\n",
        "    state_tax: float | None = Field(\n",
        "        0.0, description=\"Amount deducted for state income tax, if applicable.\"\n",
        "    )\n",
        "    social_security: float = Field(..., description=\"Amount deducted for Social Security contributions.\")\n",
        "    medicare: float = Field(..., description=\"Amount deducted for Medicare contributions.\")\n",
        "    other_deductions: float | None = Field(\n",
        "        0.0, description=\"Sum of any other deductions (e.g., health insurance, retirement plan).\"\n",
        "    )\n",
        "    net_income: float = Field(..., description=\"Total income after all deductions (take-home pay).\")\n",
        "    payment_date: date = Field(..., description=\"Date the payment was issued (YYYY-MM-DD).\")\n",
        "    hours_worked: float | None = Field(\n",
        "        None, description=\"Total hours worked in the pay period, if applicable.\"\n",
        "    )\n",
        "    hourly_rate: float | None = Field(\n",
        "        None, description=\"Employee's hourly rate, if applicable.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "06d34a6f08d9"
      },
      "outputs": [],
      "source": [
        "# Define generation config for Payslip: temperature=0 for deterministic, structured output based on the Pydantic schema.\n",
        "payslip_config = GenerateContentConfig(\n",
        "    system_instruction=entity_extraction_system_instruction,\n",
        "    temperature=0, # Use 0 for deterministic and structured output based on schema\n",
        "    response_schema=Payslip,\n",
        "    response_mime_type=JSON_MIME_TYPE,\n",
        ")\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        \"The following document is a Payslip.\", # Contextual prompt for the model\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/earnings_statement.pdf\",\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "    ],\n",
        "    generation_config=payslip_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "230b3ae51289"
      },
      "outputs": [],
      "source": [
        "print(\"\\n-------Extracted Entities--------\")\n",
        "print(response.parsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhtahn_jTZKC"
      },
      "source": [
        "## Document Classification\n",
        "\n",
        "Document classification is the process for identifying the type of document. For example, invoice, W-2, receipt, etc.\n",
        "\n",
        "In this example, you will use a [sample tax form (W-9)](https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/w9.pdf) and get the specific type of document from a specified `Enum`.\n",
        "The `classification_prompt` guides the model to categorize the document based on the `DocumentCategory` Enum provided in the schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "d797c2bfb490"
      },
      "outputs": [],
      "source": [
        "classification_prompt = \"\"\"You are a document classification specialist. Given a document, your task is to find which category the document belongs to from the document categories provided in the schema.\"\"\"\n",
        "\n",
        "\n",
        "class DocumentCategory(Enum):\n",
        "    TAX_1040_2019 = \"1040_2019\"\n",
        "    TAX_1040_2020 = \"1040_2020\"\n",
        "    TAX_1099_R = \"1099-r\"\n",
        "    BANK_STATEMENT = \"bank_statement\"\n",
        "    CREDIT_CARD_STATEMENT = \"credit_card_statement\"\n",
        "    EXPENSE = \"expense\"\n",
        "    TAX_1120S_2019 = \"form_1120S_2019\"\n",
        "    TAX_1120S_2020 = \"form_1120S_2020\"\n",
        "    INVESTMENT_RETIREMENT_STATEMENT = \"investment_retirement_statement\"\n",
        "    INVOICE = \"invoice\"\n",
        "    PAYSTUB = \"paystub\"\n",
        "    PROPERTY_INSURANCE = \"property_insurance\"\n",
        "    PURCHASE_ORDER = \"purchase_order\"\n",
        "    UTILITY_STATEMENT = \"utility_statement\"\n",
        "    W2 = \"w2\"\n",
        "    W9 = \"w9\"\n",
        "    DRIVER_LICENSE = \"driver_license\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dcab4a008a5"
      },
      "outputs": [],
      "source": [
        "# Define generation config for Document Classification: temperature=0 for deterministic output.\n",
        "# The response_schema is the Enum DocumentCategory, and response_mime_type is ENUM_MIME_TYPE for the model to return one of the enum values.\n",
        "doc_classification_config = GenerateContentConfig(\n",
        "    system_instruction=classification_prompt,\n",
        "    temperature=0, # Use 0 for deterministic category selection\n",
        "    response_schema=DocumentCategory,\n",
        "    response_mime_type=ENUM_MIME_TYPE,\n",
        ")\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        \"Classify the following document.\",\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/w9.pdf\",\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "    ],\n",
        "    generation_config=doc_classification_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "200922ddac39"
      },
      "outputs": [],
      "source": [
        "print(\"\\n-------Document Classification--------\")\n",
        "print(response.text)\n",
        "print(response.parsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d99b968e9faa"
      },
      "source": [
        "You can see that Gemini successfully categorized the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c41c7273b66"
      },
      "source": [
        "### Chaining Classification and Extraction\n",
        "\n",
        "These techniques can also be chained together to extract any number of document types.\n",
        "\n",
        "For example, if you have multiple types of documents to process, you can send each document to Gemini with a classification prompt, then based on that output, you can write logic to decide which extraction prompt to use.\n",
        "\n",
        "These are the sample documents:\n",
        "\n",
        "- [US Driver License](https://storage.googleapis.com/cloud-samples-data/documentai/SampleDocuments/US_DRIVER_LICENSE_PROCESSOR/dl3.pdf)\n",
        "- [Invoice](https://storage.googleapis.com/cloud-samples-data/documentai/SampleDocuments/INVOICE_PROCESSOR/google_invoice.pdf)\n",
        "- [Form W-2](https://storage.googleapis.com/cloud-samples-data/documentai/SampleDocuments/FORM_W2_PROCESSOR/2020FormW-2.pdf)\n",
        "\n",
        "The following cells define Pydantic models for W2 forms and Driver's Licenses. The `W2Form` schema is then exported to JSON and will be dynamically loaded in the subsequent cell. This demonstrates how schemas can be managed and versioned outside the main codebase if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "69fd5883a812"
      },
      "outputs": [],
      "source": [
        "class W2Form(BaseModel):\n",
        "    control_number: str | None = Field(None, description=\"Control number from the W-2 form, if present.\")\n",
        "    ein: str = Field(..., description=\"Employer Identification Number (EIN).\")\n",
        "\n",
        "    employee_first_name: str = Field(..., description=\"Employee's first name.\")\n",
        "    employee_last_name: str = Field(..., description=\"Employee's last name.\")\n",
        "    employee_address_street: str = Field(..., description=\"Employee's street address.\")\n",
        "    employee_address_city: str = Field(..., description=\"Employee's city.\")\n",
        "    employee_address_state: str = Field(..., description=\"Employee's state (abbreviation, e.g., CA).\" )\n",
        "    employee_address_zip: str = Field(..., description=\"Employee's ZIP code.\")\n",
        "\n",
        "    employer_name: str = Field(..., description=\"Employer's name.\")\n",
        "    employer_address_street: str = Field(..., description=\"Employer's street address.\")\n",
        "    employer_address_city: str = Field(..., description=\"Employer's city.\")\n",
        "    employer_address_state: str = Field(..., description=\"Employer's state (abbreviation, e.g., CA).\" )\n",
        "    employer_address_zip: str = Field(..., description=\"Employer's ZIP code.\")\n",
        "    employer_state_id_number: str | None = Field(None, description=\"Employer's state ID number, if applicable.\")\n",
        "\n",
        "    wages_tips_other_compensation: float = Field(..., description=\"Box 1: Wages, tips, other compensation.\")\n",
        "    federal_income_tax_withheld: float = Field(..., description=\"Box 2: Federal income tax withheld.\")\n",
        "    social_security_wages: float = Field(..., description=\"Box 3: Social security wages.\")\n",
        "    social_security_tax_withheld: float = Field(..., description=\"Box 4: Social security tax withheld.\")\n",
        "    medicare_wages_and_tips: float = Field(..., description=\"Box 5: Medicare wages and tips.\")\n",
        "    medicare_tax_withheld: float = Field(..., description=\"Box 6: Medicare tax withheld.\")\n",
        "\n",
        "    state: str | None = Field(None, description=\"Box 15: State.\")\n",
        "    state_wages_tips_etc: float | None = Field(None, description=\"Box 16: State wages, tips, etc.\")\n",
        "    state_income_tax: float | None = Field(None, description=\"Box 17: State income tax.\")\n",
        "\n",
        "    box_12_code: str | None = Field(None, description=\"Box 12 code, if present (e.g., DD, W).\" )\n",
        "    box_12_value: str | None = Field(None, description=\"Box 12 value associated with the code.\")\n",
        "\n",
        "    form_year: int = Field(..., description=\"The tax year of the W-2 form (e.g., 2020).\" )\n",
        "\n",
        "\n",
        "class DriversLicense(BaseModel):\n",
        "    address: str = Field(\n",
        "        ..., title=\"Address\", description=\"Full address of the individual on the license.\"\n",
        "    )\n",
        "    date_of_birth: date = Field(\n",
        "        ..., title=\"Date of Birth\", description=\"Birthdate of the individual (YYYY-MM-DD).\"\n",
        "    )\n",
        "    document_id: str = Field(\n",
        "        ...,\n",
        "        title=\"Document ID\",\n",
        "        description=\"The unique document ID or license number for the driver's license.\",\n",
        "    )\n",
        "    expiration_date: date = Field(\n",
        "        ...,\n",
        "        title=\"Expiration Date\",\n",
        "        description=\"Expiration date of the driver's license (YYYY-MM-DD).\",\n",
        "    )\n",
        "    family_name: str = Field(\n",
        "        ...,\n",
        "        title=\"Family Name\",\n",
        "        description=\"The family name (last name or surname) of the individual.\",\n",
        "    )\n",
        "    given_names: str = Field(\n",
        "        ...,\n",
        "        title=\"Given Names\",\n",
        "        description=\"The given names (first and middle names) of the individual.\",\n",
        "    )\n",
        "    issue_date: date = Field(\n",
        "        ..., title=\"Issue Date\", description=\"Issue date of the driver's license (YYYY-MM-DD).\"\n",
        "    )\n",
        "\n",
        "# Export the W2Form schema to a JSON string for later dynamic loading.\n",
        "w2form_schema_json = W2Form.schema_json(indent=2)\n",
        "print(\"W2Form JSON Schema:\")\n",
        "print(w2form_schema_json)\n",
        "\n",
        "# Map classification types to Pydantic schemas for entity extraction.\n",
        "# The W2Form mapping will be updated in the next cell using the dynamically loaded schema.\n",
        "classification_to_schema = {\n",
        "    DocumentCategory.INVOICE: Invoice,\n",
        "    DocumentCategory.W2: W2Form, \n",
        "    DocumentCategory.DRIVER_LICENSE: DriversLicense,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c806b4d757e"
      },
      "outputs": [],
      "source": [
        "# Dynamically load the W2Form schema from the JSON string defined in the previous cell.\n",
        "W2FormLoaded = create_model_from_json_schema(w2form_schema_json, \"W2FormLoaded\")\n",
        "print(\"Successfully loaded W2Form from JSON schema\")\n",
        "\n",
        "# Update the classification_to_schema dictionary to use the loaded schema for W2 forms.\n",
        "classification_to_schema[DocumentCategory.W2] = W2FormLoaded\n",
        "\n",
        "gcs_uris = [\n",
        "    \"gs://cloud-samples-data/documentai/SampleDocuments/US_DRIVER_LICENSE_PROCESSOR/dl3.pdf\",\n",
        "    \"gs://cloud-samples-data/documentai/SampleDocuments/INVOICE_PROCESSOR/google_invoice.pdf\",\n",
        "    \"gs://cloud-samples-data/documentai/SampleDocuments/FORM_W2_PROCESSOR/2020FormW-2.pdf\",\n",
        "]\n",
        "\n",
        "for gcs_uri in gcs_uris:\n",
        "    print(f\"\\nFile: {gcs_uri}\\n\")\n",
        "\n",
        "    # Config for the classification step.\n",
        "    classification_config = GenerateContentConfig(\n",
        "        system_instruction=classification_prompt,\n",
        "        temperature=0,\n",
        "        response_schema=DocumentCategory,\n",
        "        response_mime_type=ENUM_MIME_TYPE,\n",
        "    )\n",
        "    classification_response = make_gemini_request(\n",
        "        client,\n",
        "        MODEL_ID,\n",
        "        contents=[\n",
        "            \"Classify the following document.\",\n",
        "            Part.from_uri(file_uri=gcs_uri, mime_type=PDF_MIME_TYPE),\n",
        "        ],\n",
        "        generation_config=classification_config,\n",
        "    )\n",
        "\n",
        "    if not classification_response or not classification_response.text:\n",
        "        print(\"Skipping extraction due to classification error or empty response.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Document Classification: {classification_response.text}\")\n",
        "\n",
        "    # Get Extraction schema based on Classification\n",
        "    extraction_schema = classification_to_schema.get(classification_response.parsed)\n",
        "\n",
        "    if not extraction_schema:\n",
        "        print(f\"Document does not belong to a specified class. Skipping extraction.\")\n",
        "        continue\n",
        "\n",
        "    # Config for the entity extraction step, using entity_extraction_system_instruction.\n",
        "    extraction_config = GenerateContentConfig(\n",
        "        system_instruction=entity_extraction_system_instruction, \n",
        "        temperature=0,\n",
        "        response_schema=extraction_schema,\n",
        "        response_mime_type=JSON_MIME_TYPE,\n",
        "    )\n",
        "    extraction_response = make_gemini_request(\n",
        "        client,\n",
        "        MODEL_ID,\n",
        "        contents=[\n",
        "            f\"Extract the entities from the following {classification_response.text} document.\",\n",
        "            Part.from_uri(file_uri=gcs_uri, mime_type=PDF_MIME_TYPE),\n",
        "        ],\n",
        "        generation_config=extraction_config,\n",
        "    )\n",
        "\n",
        "    if not extraction_response:\n",
        "        print(\"Skipping entity printing due to extraction error.\")\n",
        "        continue\n",
        "\n",
        "    print(\"\\n-------Extracted Entities--------\")\n",
        "    print(extraction_response.parsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "322abdb6d63d"
      },
      "source": [
        "## Document Question Answering\n",
        "\n",
        "Gemini can be used to answer questions about a document. The `qa_system_instruction` guides the model to act as a question-answering specialist, using the provided document as context.\n",
        "\n",
        "This example answers a question about the Transformer model paper [\"Attention is all you need\"](https://arxiv.org/pdf/1706.03762), we will be loading the PDF file directly from the source on [arXiv](https://arxiv.org)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "f47a8b63ce13"
      },
      "outputs": [],
      "source": [
        "qa_system_instruction = \"You are a question answering specialist. Given a question and a context, your task is to provide the answer to the question based on the context provided. Give the answer first, followed by an explanation.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "636f158c24fb"
      },
      "outputs": [],
      "source": [
        "# Send Q&A Prompt to Gemini\n",
        "# Define generation config for Q&A: temperature=0 for more factual, less creative answers.\n",
        "qa_config = GenerateContentConfig(\n",
        "    system_instruction=qa_system_instruction,\n",
        "    temperature=0,\n",
        "    response_mime_type=\"text/plain\", # Expecting a plain text answer\n",
        ")\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        \"What is the attention mechanism?\", # The question\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\", # The document context\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "    ],\n",
        "    generation_config=qa_config,\n",
        ")\n",
        "\n",
        "if response:\n",
        "    print(f\"Answer: {response.text}\")\n",
        "else:\n",
        "    print(\"No answer due to an error.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5881bdeb3b0"
      },
      "source": [
        "## Document Summarization\n",
        "\n",
        "Gemini can also be used to summarize or paraphrase a document's contents. Your prompt can specify how detailed the summary should be or specific formatting, such as bullet points or paragraphs.\n",
        "The `summarization_system_instruction` directs the model to act as a professional summarizer, focusing on key details including descriptions of images, tables, and graphs, while avoiding external information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "85b23b916ffa"
      },
      "outputs": [],
      "source": [
        "summarization_system_instruction = \"\"\"You are a professional document summarization specialist. Given a document, your task is to provide a detailed summary of the content of the document.\n",
        "\n",
        "If it includes images, provide descriptions of the images.\n",
        "If it includes tables, extract all elements of the tables.\n",
        "If it includes graphs, explain the findings in the graphs.\n",
        "Do not include any numbers that are not mentioned in the document.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01c2c8c947e0"
      },
      "outputs": [],
      "source": [
        "# Send Summarization Prompt to Gemini\n",
        "# Define generation config for Summarization: temperature=0 for a more focused and factual summary.\n",
        "summarization_config = GenerateContentConfig(\n",
        "    system_instruction=summarization_system_instruction,\n",
        "    temperature=0, # Lower temperature for more factual summary\n",
        "    response_mime_type=\"text/plain\", # Expecting a plain text summary\n",
        ")\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        \"Summarize the following document.\", # The summarization request\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/fdic_board_meeting.pdf\", # The document to summarize\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "    ],\n",
        "    generation_config=summarization_config,\n",
        ")\n",
        "\n",
        "if response:\n",
        "    display(Markdown(f\"### Document Summary\"))\n",
        "    display(Markdown(response.text))\n",
        "else:\n",
        "    print(\"No summary due to an error.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85015f00a36f"
      },
      "source": [
        "## Table parsing from documents\n",
        "\n",
        "Gemini can parse contents of a table and return it in a structured format, such as HTML or markdown. The following example asks for an HTML representation of a table within a document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "b780755d42e0"
      },
      "outputs": [],
      "source": [
        "table_extraction_prompt = \"\"\"What is the HTML code of the table in this document?\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ad318a19c6a"
      },
      "outputs": [],
      "source": [
        "# Send Table Extraction Prompt to Gemini\n",
        "# Define generation config for Table Extraction: temperature=0 for direct HTML output.\n",
        "table_config = GenerateContentConfig(temperature=0) # Temperature 0 for precise extraction\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        table_extraction_prompt,\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/salary_table.pdf\",\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "    ],\n",
        "    generation_config=table_config,\n",
        ")\n",
        "\n",
        "if response and response.text:\n",
        "    display(Markdown(response.text)) # Display the raw HTML table as Markdown\n",
        "    \n",
        "    html_table_str = response.text\n",
        "    # Remove markdown code fences (```html and ```) if present around the HTML string\n",
        "    if html_table_str.startswith(\"```html\"):\n",
        "        html_table_str = html_table_str[7:]\n",
        "    if html_table_str.endswith(\"```\"):\n",
        "        html_table_str = html_table_str[:-3]\n",
        "    html_table_str = html_table_str.strip()\n",
        "\n",
        "    # Define a simple HTML parser to extract table data into a list of lists\n",
        "    class SimpleTableParser(HTMLParser):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.in_td = False # Flag to indicate if currently inside a <td> tag\n",
        "            self.in_th = False # Flag to indicate if currently inside a <th> tag\n",
        "            self.current_row = [] # Holds data for the current row being parsed\n",
        "            self.table_data = [] # List of all rows (each row is a list of cell data)\n",
        "            self.current_cell_data = \"\" # Accumulates data within a cell\n",
        "\n",
        "        def handle_starttag(self, tag, attrs):\n",
        "            if tag == \"tr\": # Start of a table row\n",
        "                self.current_row = []\n",
        "            elif tag == \"td\": # Start of a table data cell\n",
        "                self.in_td = True\n",
        "                self.current_cell_data = \"\"\n",
        "            elif tag == \"th\": # Start of a table header cell\n",
        "                self.in_th = True\n",
        "                self.current_cell_data = \"\"\n",
        "\n",
        "        def handle_endtag(self, tag):\n",
        "            if tag == \"tr\": # End of a table row\n",
        "                if self.current_row: \n",
        "                    self.table_data.append(self.current_row)\n",
        "            elif tag == \"td\": # End of a table data cell\n",
        "                self.in_td = False\n",
        "                self.current_row.append(self.current_cell_data.strip())\n",
        "                self.current_cell_data = \"\"\n",
        "            elif tag == \"th\": # End of a table header cell\n",
        "                self.in_th = False\n",
        "                self.current_row.append(self.current_cell_data.strip())\n",
        "                self.current_cell_data = \"\"\n",
        "\n",
        "        def handle_data(self, data):\n",
        "            if self.in_td or self.in_th: # Accumulate data if inside a <td> or <th>\n",
        "                self.current_cell_data += data\n",
        "\n",
        "    parser = SimpleTableParser()\n",
        "    parser.feed(html_table_str) # Feed the HTML table string to the parser\n",
        "    parsed_table_list_of_lists = parser.table_data\n",
        "\n",
        "    print(\"\\n-------Parsed Table (List of Lists)--------\")\n",
        "    for row in parsed_table_list_of_lists:\n",
        "        print(row)\n",
        "\n",
        "    # Convert to list of dictionaries if headers are present\n",
        "    if parsed_table_list_of_lists and len(parsed_table_list_of_lists) > 0:\n",
        "        headers = parsed_table_list_of_lists[0] # Assume the first row contains headers\n",
        "        data_rows = parsed_table_list_of_lists[1:]\n",
        "        if headers and data_rows: # Check if both headers and data rows exist\n",
        "            list_of_dicts = [dict(zip(headers, row)) for row in data_rows]\n",
        "            print(\"\\n-------Parsed Table (List of Dictionaries)--------\")\n",
        "            for item in list_of_dicts:\n",
        "                print(item)\n",
        "        elif headers: # Only headers, no data rows\n",
        "             print(\"\\n-------Parsed Table (List of Dictionaries)--------\")\n",
        "             print(\"Only headers found, no data rows to convert to dictionaries.\")\n",
        "        else: # No clear headers or no data rows\n",
        "             print(\"\\n-------Parsed Table (List of Dictionaries)--------\")\n",
        "             print(\"Could not determine headers or no data rows available for dictionary conversion.\")\n",
        "    else:\n",
        "        print(\"\\n-------Parsed Table (List of Dictionaries)--------\")\n",
        "        print(\"Parsed table is empty or malformed, cannot convert to list of dictionaries.\")\n",
        "else:\n",
        "    print(\"No table extracted due to an error or empty response.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ebe7318abf6"
      },
      "source": [
        "## Document Translation\n",
        "\n",
        "Gemini can translate documents between languages. This example translates meeting notes from English into French and Spanish. The `translation_prompt` instructs the model to perform the translation and label each language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "c03f55376e76"
      },
      "outputs": [],
      "source": [
        "translation_prompt = \"\"\"Translate the first paragraph into French and Spanish. Label each paragraph with the target language.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e22d1c06508"
      },
      "outputs": [],
      "source": [
        "# Send Translation Prompt to Gemini\n",
        "# Define generation config for Translation: temperature=0 for more literal and accurate translation.\n",
        "translation_config = GenerateContentConfig(temperature=0)\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        translation_prompt,\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/fdic_board_meeting.pdf\",\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "    ],\n",
        "    generation_config=translation_config,\n",
        ")\n",
        "\n",
        "if response:\n",
        "    display(Markdown(f\"### Translations\"))\n",
        "    display(Markdown(response.text))\n",
        "else:\n",
        "    print(\"No translation due to an error.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e8111f438db"
      },
      "source": [
        "## Document Comparison\n",
        "\n",
        "Gemini can compare and contrast the contents of multiple documents. This example finds the changes in the IRS Form 1040 between 2013 and 2023.\n",
        "\n",
        "Note: when working with multiple documents, the order can matter and should be specified in your prompt. Here, the `comparison_prompt` clarifies the order of the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "62bd15c5553f"
      },
      "outputs": [],
      "source": [
        "comparison_prompt = \"\"\"The first document is from 2013, the second one from 2023. How did the standard deduction evolve?\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5f07456ed8d"
      },
      "outputs": [],
      "source": [
        "# Send Comparison Prompt to Gemini\n",
        "# Define generation config for Comparison: temperature=0 for a factual comparison.\n",
        "comparison_config = GenerateContentConfig(temperature=0)\n",
        "response = make_gemini_request(\n",
        "    client,\n",
        "    MODEL_ID,\n",
        "    contents=[\n",
        "        comparison_prompt,\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/form_1040_2013.pdf\",\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/form_1040_2023.pdf\",\n",
        "            mime_type=PDF_MIME_TYPE,\n",
        "        ),\n",
        "    ],\n",
        "    generation_config=comparison_config,\n",
        ")\n",
        "\n",
        "if response:\n",
        "    display(Markdown(f\"### Comparison\"))\n",
        "    display(Markdown(response.text))\n",
        "else:\n",
        "    print(\"No comparison due to an error.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "async-processing-markdown"
      },
      "source": [
        "### Asynchronous Processing for Multiple Documents\n",
        "\n",
        "When processing multiple documents, making sequential API calls can be time-consuming because the program waits for each call to complete before starting the next. Asynchronous processing can significantly speed up I/O-bound operations like these by allowing the program to initiate multiple requests and then process them as they complete, rather than one by one.\n",
        "\n",
        "Python's `asyncio` library is the standard way to handle such tasks. For optimal performance with the Gemini API, you would typically use asynchronous methods provided by the `google-genai` SDK. If the SDK offers methods like `async_generate_content()`, those should be preferred.\n",
        "\n",
        "Below is a *hypothetical* code snippet to illustrate the concept. Note that the `async_generate_content` method is fictional for this example, and you'd need to consult the SDK documentation for the actual asynchronous methods available.\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "# from google.genai import ... # Actual imports would depend on SDK's async support\n",
        "# from google.genai.types import ...\n",
        "\n",
        "# Hypothetical asynchronous function to process a single document\n",
        "async def process_document_async(client, model_id, document_content, generation_config):\n",
        "    # This is a placeholder for the SDK's actual async call\n",
        "    # print(f\"Starting processing for: {document_content[:30]}...\")\n",
        "    # response = await client.models.async_generate_content( # Fictional method\n",
        "    #     model=model_id,\n",
        "    #     contents=[document_content, Part.from_uri(...)], # Example content\n",
        "    #     config=generation_config\n",
        "    # )\n",
        "    # await asyncio.sleep(1) # Simulate I/O-bound operation (API call)\n",
        "    # return f\"Processed: {document_content[:20]}... -> {response.text[:30]}...\"\n",
        "    \n",
        "    # Using the synchronous make_gemini_request in a thread for asyncio compatibility (conceptual)\n",
        "    # In a real scenario, you'd use the SDK's native async methods if available.\n",
        "    loop = asyncio.get_event_loop()\n",
        "    response = await loop.run_in_executor(\n",
        "        None, # Uses the default ThreadPoolExecutor\n",
        "        make_gemini_request, # Your existing synchronous function\n",
        "        client, \n",
        "        model_id, \n",
        "        [document_content], # Assuming contents is a list for make_gemini_request \n",
        "        generation_config\n",
        "    )\n",
        "    await asyncio.sleep(1) # Simulate additional async work or ensure yield\n",
        "    if response and response.text:\n",
        "        return f\"Processed (simulated async): {document_content[:20]}... -> {response.text[:30]}...\"\n",
        "    return f\"Failed or empty (simulated async): {document_content[:20]}...\"\n",
        "\n",
        "async def main_async_processing(client, model_id, document_parts, generation_config):\n",
        "    tasks = []\n",
        "    for doc_part in document_parts:\n",
        "        # Each Part object is assumed to be a document or part of a document for processing\n",
        "        tasks.append(process_document_async(client, model_id, doc_part, generation_config))\n",
        "    \n",
        "    results = await asyncio.gather(*tasks)\n",
        "    \n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "# Example of how you might run this (conceptual):\n",
        "# Assuming 'client', 'MODEL_ID', 'sample_doc_parts', 'some_config' are defined:\n",
        "# sample_doc_parts = [Part.from_uri(...), Part.from_uri(...)] # List of document parts\n",
        "# some_config = GenerateContentConfig(...)\n",
        "#\n",
        "# To run in a Jupyter Notebook, you might need to use nest_asyncio or ensure the event loop is managed:\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "#\n",
        "# asyncio.run(main_async_processing(client, MODEL_ID, sample_doc_parts, some_config))\n",
        "```\n",
        "\n",
        "**Caveats for Jupyter Notebooks**:\n",
        "Running `asyncio` code, especially `asyncio.run()`, directly in a Jupyter Notebook cell can lead to a `RuntimeError` if an event loop is already running (which is often the case in Jupyter environments). To manage this, you might need to:\n",
        "- Use the `nest_asyncio` library: `import nest_asyncio; nest_asyncio.apply()` at the beginning of your notebook.\n",
        "- Alternatively, use `await main_async_processing(...)` directly in a cell if you are in an environment that supports top-level await (like IPython 7.0+).\n",
        "\n",
        "Always refer to the latest `google-genai` SDK documentation for the recommended way to perform asynchronous operations."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "document_processing.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
